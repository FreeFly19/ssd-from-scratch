{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses, callbacks\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {1: 'Red Square', 2: 'Red Triangle', 3: 'Yellow Square', 4: 'Yellow Traingle'}\n",
    "def generate():\n",
    "    img = np.zeros((32, 32, 3), dtype=np.float)\n",
    "    \n",
    "    c = random.randint(1, 4) \n",
    "    \n",
    "    size = random.randint(6, 15)\n",
    "    pos_x = random.randint(0, 31 - size)\n",
    "    pos_y = random.randint(0, 31 - size)\n",
    "    img[pos_x:pos_x + size, pos_y:pos_y + size] = [255.0, 0.0, 0.0] if c < 3 else [255.0, 255.0, 0.0]\n",
    "    if (c % 2 == 0):\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                if i < j:\n",
    "                    img[pos_x + i, pos_y + j] = [0, 0, 0]\n",
    "            \n",
    "    \n",
    "    return img, float(size), float(pos_x), float(pos_y), c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(img):\n",
    "    return Image.fromarray(img.astype(np.int8), mode='RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAASUlEQVR4nO3NiwkAIAwD0eL+O+sC1X4SQTA3wD0zpZT6sMkejtuGA3ANHyAaW4BlnACKEQC4EQOgkQIQIwu0jQLQM2pAz1Dq9RYcJgwLq39ZjgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FBFE062D320>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, _, _, _, _ = generate()\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in range(10000):\n",
    "    t = generate()\n",
    "    X.append(t[0] / 255.0)\n",
    "    y.append((t[1] / 32.0, t[2] / 32.0, t[3] / 32.0, int(t[4] == 1), int(t[4] == 2), int(t[4] == 3), int(t[4] == 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lc_model(conv_filters = 8):\n",
    "    inp = layers.Input((32, 32, 3))\n",
    "    conv_1_1 = layers.Conv2D(conv_filters*2, 3, padding='same')(inp)\n",
    "    pool_1_1 = layers.MaxPool2D()(conv_1_1)\n",
    "    \n",
    "    conv_2_1 = layers.Conv2D(conv_filters, 3, padding='same', activation='relu')(pool_1_1)\n",
    "    pool_2_1 = layers.MaxPool2D()(conv_2_1)\n",
    "    \n",
    "    conv_3_1 = layers.Conv2D(conv_filters, 3, padding='same', activation='relu')(pool_2_1)\n",
    "    pool_3_1 = layers.MaxPool2D()(conv_3_1)\n",
    "    \n",
    "\n",
    "    conv_4_1_l = layers.Conv2D(conv_filters, 3, padding='same', activation='relu')(pool_3_1)\n",
    "    pool_4_1_l = layers.MaxPool2D()(conv_4_1_l)\n",
    "    \n",
    "    conv_5_1_l = layers.Conv2D(conv_filters*2, 3, padding='same', activation='relu')(pool_4_1_l)\n",
    "    pool_5_1_l = layers.MaxPool2D()(conv_5_1_l)\n",
    "    out1 = layers.Conv2D(3, 1, activation='relu', name = 'localization')(pool_5_1_l)\n",
    "    \n",
    "    \n",
    "    conv_4_1_c = layers.Conv2D(conv_filters, 3, padding='same', activation='relu')(pool_3_1)\n",
    "    pool_4_1_c = layers.MaxPool2D()(conv_4_1_c)\n",
    "    \n",
    "    conv_5_1_c = layers.Conv2D(conv_filters, 3, padding='same', activation='relu')(pool_4_1_c)\n",
    "    pool_5_1_c = layers.MaxPool2D()(conv_5_1_c)\n",
    "\n",
    "    out2 = layers.Conv2D(4, 1, activation='softmax', name = 'classification')(pool_5_1_c)\n",
    "\n",
    "    return models.Model(inputs=inp, outputs = [out1, out2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lc_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localization_loss(y_true, y_pred):\n",
    "    return losses.MSE(y_true, y_pred) * 100\n",
    "\n",
    "def classification_loss(y_true, y_pred): \n",
    "    return losses.categorical_crossentropy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(), \n",
    "              loss = [localization_loss, classification_loss],\n",
    "              metrics=['accuracy', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 62s 8ms/step - loss: 0.4683 - localization_loss: 0.2201 - classification_loss: 0.2482 - localization_acc: 0.8889 - classification_acc: 0.8976 - val_loss: 0.0653 - val_localization_loss: 0.0609 - val_classification_loss: 0.0044 - val_localization_acc: 0.9260 - val_classification_acc: 1.0000\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.0810 - localization_loss: 0.0677 - classification_loss: 0.0133 - localization_acc: 0.9260 - classification_acc: 0.9971 - val_loss: 0.0631 - val_localization_loss: 0.0600 - val_classification_loss: 0.0031 - val_localization_acc: 0.9470 - val_classification_acc: 0.9990\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 62s 8ms/step - loss: 0.0634 - localization_loss: 0.0465 - classification_loss: 0.0169 - localization_acc: 0.9356 - classification_acc: 0.9981 - val_loss: 0.0275 - val_localization_loss: 0.0266 - val_classification_loss: 9.0235e-04 - val_localization_acc: 0.9500 - val_classification_acc: 1.0000\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 59s 7ms/step - loss: 0.0570 - localization_loss: 0.0402 - classification_loss: 0.0167 - localization_acc: 0.9430 - classification_acc: 0.9968 - val_loss: 0.0263 - val_localization_loss: 0.0253 - val_classification_loss: 0.0011 - val_localization_acc: 0.9570 - val_classification_acc: 1.0000\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.0895 - localization_loss: 0.0343 - classification_loss: 0.0551 - localization_acc: 0.9417 - classification_acc: 0.9960 - val_loss: 4.4889 - val_localization_loss: 0.3344 - val_classification_loss: 4.1545 - val_localization_acc: 0.7800 - val_classification_acc: 0.6460\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.0807 - localization_loss: 0.0349 - classification_loss: 0.0458 - localization_acc: 0.9471 - classification_acc: 0.9955 - val_loss: 0.0230 - val_localization_loss: 0.0228 - val_classification_loss: 2.3133e-04 - val_localization_acc: 0.9365 - val_classification_acc: 1.0000\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.0472 - localization_loss: 0.0299 - classification_loss: 0.0173 - localization_acc: 0.9429 - classification_acc: 0.9975 - val_loss: 0.0339 - val_localization_loss: 0.0338 - val_classification_loss: 8.6053e-05 - val_localization_acc: 0.9395 - val_classification_acc: 1.0000\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 61s 8ms/step - loss: 0.0699 - localization_loss: 0.0279 - classification_loss: 0.0420 - localization_acc: 0.9486 - classification_acc: 0.9964 - val_loss: 0.0476 - val_localization_loss: 0.0467 - val_classification_loss: 8.5176e-04 - val_localization_acc: 0.9455 - val_classification_acc: 1.0000\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 60s 7ms/step - loss: 0.0302 - localization_loss: 0.0262 - classification_loss: 0.0040 - localization_acc: 0.9486 - classification_acc: 0.9991 - val_loss: 0.0252 - val_localization_loss: 0.0251 - val_classification_loss: 1.4874e-04 - val_localization_acc: 0.9375 - val_classification_acc: 1.0000\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 61s 8ms/step - loss: 0.0489 - localization_loss: 0.0245 - classification_loss: 0.0244 - localization_acc: 0.9501 - classification_acc: 0.9982 - val_loss: 0.0237 - val_localization_loss: 0.0237 - val_classification_loss: 7.2145e-05 - val_localization_acc: 0.9465 - val_classification_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "X = np.asarray(X).reshape(-1, 32, 32, 3)\n",
    "y1 = np.asarray(y)[:, :3]\n",
    "y2 = np.asarray(y)[:, 3:]\n",
    "\n",
    "def fit(batch, epochs):\n",
    "    model.fit(\n",
    "        x = X,\n",
    "        y=[y1, y2],\n",
    "        epochs=epochs,\n",
    "        batch_size=batch,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[\n",
    "            callbacks.TensorBoard(),\n",
    "            callbacks.ReduceLROnPlateau()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "fit(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAASElEQVR4nO3NwQ0AIAjFUOP+O+sAKCJ8bu25yRuDGlo/8+w2kkDcyANBowREjCrwNASAb2gAx5ABN0MJHA0xYA09YA0iIqL+Ng5ODAvVvba3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FBD04413F60>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, size, col, row, c = generate()\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(np.asarray(img).reshape(-1, 32, 32, 3) / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 12.0 rounded prediction: 12.0, raw 11.960250854492188\n",
      "Left: 3.0 rounded prediction: 3.0, raw 3.38435959815979\n",
      "Top: 17.0 rounded prediction: 17.0, raw 17.277193069458008\n",
      "Class: Red Triangle  prediction: Red Triangle\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size: {size} rounded prediction: {round(preds[0][0][0][0][0] * 32)}, raw {preds[0][0][0][0][0] * 32}\")\n",
    "print(f\"Left: {col} rounded prediction: {round(preds[0][0][0][0][1] * 32)}, raw {preds[0][0][0][0][1] * 32}\")\n",
    "print(f\"Top: {row} rounded prediction: {round(preds[0][0][0][0][2] * 32)}, raw {preds[0][0][0][0][2] * 32}\")\n",
    "print(f\"Class: {classes[c]}  prediction: {classes[np.argmax(preds[1][0][0][0]) + 1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
