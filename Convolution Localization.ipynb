{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses, callbacks\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    img = np.zeros((32, 32), dtype=float)\n",
    "    size = random.randint(3, 9)\n",
    "    pos_x = random.randint(0, 31 - size)\n",
    "    pos_y = random.randint(0, 31 - size)\n",
    "    img[pos_x:pos_x + size, pos_y:pos_y + size] = 255.0\n",
    "    \n",
    "    return img, size, pos_x, pos_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(img):\n",
    "    return Image.fromarray(img).convert(\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAAAH0lEQVR4nGNgGAXDBzAimP+xiDEwMBEyYYQoGAVEAgBpXwESqMslyAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32 at 0x7FB3B4491CF8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, _, _, _ = generate()\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in range(10000):\n",
    "    t = generate()\n",
    "    X.append(t[0] / 255.0)\n",
    "    y.append((t[1] / 10, t[2] / 32, t[3] / 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_model(conv_filters = 4):\n",
    "    inp = layers.Input((32, 32, 1))\n",
    "    conv_1_1 = layers.Conv2D(conv_filters, 3, padding='same', activation='relu')(inp)\n",
    "    pool_1_1 = layers.MaxPool2D()(conv_1_1)\n",
    "    \n",
    "    conv_2_1 = layers.Conv2D(conv_filters, 3, padding='same', activation='relu')(pool_1_1)\n",
    "    pool_2_1 = layers.MaxPool2D()(conv_2_1)\n",
    "    \n",
    "    conv_3_1 = layers.Conv2D(conv_filters, 3, padding='same', activation='relu')(pool_2_1)\n",
    "    pool_3_1 = layers.MaxPool2D()(conv_3_1)\n",
    "    \n",
    "    conv_4_1 = layers.Conv2D(conv_filters*2, 3, padding='same', activation='relu')(pool_3_1)\n",
    "    pool_4_1 = layers.MaxPool2D()(conv_4_1)\n",
    "    \n",
    "    conv_5_1 = layers.Conv2D(conv_filters*4, 3, padding='same', activation='relu')(pool_4_1)\n",
    "    pool_5_1 = layers.MaxPool2D()(conv_5_1)\n",
    "    \n",
    "    conv_6_1 = layers.Conv2D(3, 1, activation='relu')(pool_5_1)\n",
    "    \n",
    "    \n",
    "    out = layers.Flatten()(conv_6_1)\n",
    "    return models.Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = l_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    return losses.MSE(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(), \n",
    "              loss=loss,\n",
    "              metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 73s 9ms/step - loss: 0.0045 - acc: 0.9144 - val_loss: 6.0696e-04 - val_acc: 0.9680\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 7s 931us/step - loss: 4.2343e-04 - acc: 0.9685 - val_loss: 4.0145e-04 - val_acc: 0.9740\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/128\n",
      "8000/8000 [==============================] - 1s 99us/step - loss: 3.3634e-04 - acc: 0.9725 - val_loss: 3.1052e-04 - val_acc: 0.9720\n",
      "Epoch 2/128\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 3.1881e-04 - acc: 0.9735 - val_loss: 3.0162e-04 - val_acc: 0.9780\n",
      "Epoch 3/128\n",
      "8000/8000 [==============================] - 1s 161us/step - loss: 3.1108e-04 - acc: 0.9732 - val_loss: 2.9409e-04 - val_acc: 0.9775\n",
      "Epoch 4/128\n",
      "8000/8000 [==============================] - 1s 126us/step - loss: 3.0315e-04 - acc: 0.9741 - val_loss: 2.8930e-04 - val_acc: 0.9730\n",
      "Epoch 5/128\n",
      "8000/8000 [==============================] - 1s 163us/step - loss: 2.9565e-04 - acc: 0.9751 - val_loss: 2.8336e-04 - val_acc: 0.9790\n",
      "Epoch 6/128\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 2.8943e-04 - acc: 0.9758 - val_loss: 2.8036e-04 - val_acc: 0.9730\n",
      "Epoch 7/128\n",
      "8000/8000 [==============================] - 1s 163us/step - loss: 2.8277e-04 - acc: 0.9769 - val_loss: 2.6626e-04 - val_acc: 0.9790\n",
      "Epoch 8/128\n",
      "8000/8000 [==============================] - 1s 126us/step - loss: 2.7286e-04 - acc: 0.9764 - val_loss: 2.6022e-04 - val_acc: 0.9785\n",
      "Epoch 9/128\n",
      "8000/8000 [==============================] - 1s 158us/step - loss: 2.6876e-04 - acc: 0.9765 - val_loss: 2.5295e-04 - val_acc: 0.9790\n",
      "Epoch 10/128\n",
      "8000/8000 [==============================] - 1s 135us/step - loss: 2.6146e-04 - acc: 0.9766 - val_loss: 2.4922e-04 - val_acc: 0.9795\n",
      "Epoch 11/128\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 2.5217e-04 - acc: 0.9779 - val_loss: 2.5260e-04 - val_acc: 0.9775\n",
      "Epoch 12/128\n",
      "8000/8000 [==============================] - 1s 123us/step - loss: 2.4721e-04 - acc: 0.9778 - val_loss: 2.3504e-04 - val_acc: 0.9790\n",
      "Epoch 13/128\n",
      "8000/8000 [==============================] - 1s 128us/step - loss: 2.4477e-04 - acc: 0.9776 - val_loss: 2.3079e-04 - val_acc: 0.9785\n",
      "Epoch 14/128\n",
      "8000/8000 [==============================] - 1s 143us/step - loss: 2.3418e-04 - acc: 0.9776 - val_loss: 2.2676e-04 - val_acc: 0.9775\n",
      "Epoch 15/128\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 2.2974e-04 - acc: 0.9779 - val_loss: 2.2513e-04 - val_acc: 0.9785\n",
      "Epoch 16/128\n",
      "8000/8000 [==============================] - 1s 117us/step - loss: 2.2176e-04 - acc: 0.9790 - val_loss: 2.1053e-04 - val_acc: 0.9795\n",
      "Epoch 17/128\n",
      "8000/8000 [==============================] - 2s 188us/step - loss: 2.1593e-04 - acc: 0.9780 - val_loss: 2.0484e-04 - val_acc: 0.9775\n",
      "Epoch 18/128\n",
      "8000/8000 [==============================] - 1s 143us/step - loss: 2.1304e-04 - acc: 0.9789 - val_loss: 2.1042e-04 - val_acc: 0.9760\n",
      "Epoch 19/128\n",
      "8000/8000 [==============================] - 1s 169us/step - loss: 2.0522e-04 - acc: 0.9792 - val_loss: 1.9848e-04 - val_acc: 0.9770\n",
      "Epoch 20/128\n",
      "8000/8000 [==============================] - 1s 185us/step - loss: 1.9978e-04 - acc: 0.9781 - val_loss: 1.9664e-04 - val_acc: 0.9760\n",
      "Epoch 21/128\n",
      "8000/8000 [==============================] - 1s 156us/step - loss: 1.9669e-04 - acc: 0.9789 - val_loss: 1.9219e-04 - val_acc: 0.9785\n",
      "Epoch 22/128\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 1.9098e-04 - acc: 0.9778 - val_loss: 1.8428e-04 - val_acc: 0.9760\n",
      "Epoch 23/128\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.8669e-04 - acc: 0.9801 - val_loss: 1.8739e-04 - val_acc: 0.9740\n",
      "Epoch 24/128\n",
      "8000/8000 [==============================] - 1s 171us/step - loss: 1.8429e-04 - acc: 0.9780 - val_loss: 1.7585e-04 - val_acc: 0.9760\n",
      "Epoch 25/128\n",
      "8000/8000 [==============================] - 1s 116us/step - loss: 1.7934e-04 - acc: 0.9785 - val_loss: 1.6626e-04 - val_acc: 0.9770\n",
      "Epoch 26/128\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 1.7128e-04 - acc: 0.9789 - val_loss: 1.7261e-04 - val_acc: 0.9740\n",
      "Epoch 27/128\n",
      "8000/8000 [==============================] - 1s 153us/step - loss: 1.6767e-04 - acc: 0.9788 - val_loss: 1.6348e-04 - val_acc: 0.9810\n",
      "Epoch 28/128\n",
      "8000/8000 [==============================] - 1s 161us/step - loss: 1.6356e-04 - acc: 0.9796 - val_loss: 1.5876e-04 - val_acc: 0.9745\n",
      "Epoch 29/128\n",
      "8000/8000 [==============================] - 1s 129us/step - loss: 1.6291e-04 - acc: 0.9792 - val_loss: 1.6651e-04 - val_acc: 0.9755\n",
      "Epoch 30/128\n",
      "8000/8000 [==============================] - 1s 108us/step - loss: 1.5587e-04 - acc: 0.9792 - val_loss: 1.5232e-04 - val_acc: 0.9790\n",
      "Epoch 31/128\n",
      "8000/8000 [==============================] - 1s 121us/step - loss: 1.5566e-04 - acc: 0.9813 - val_loss: 1.6411e-04 - val_acc: 0.9750\n",
      "Epoch 32/128\n",
      "8000/8000 [==============================] - 1s 138us/step - loss: 1.5071e-04 - acc: 0.9795 - val_loss: 1.5512e-04 - val_acc: 0.9805\n",
      "Epoch 33/128\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 1.4618e-04 - acc: 0.9810 - val_loss: 1.3837e-04 - val_acc: 0.9810\n",
      "Epoch 34/128\n",
      "8000/8000 [==============================] - 1s 184us/step - loss: 1.4197e-04 - acc: 0.9822 - val_loss: 1.3209e-04 - val_acc: 0.9805\n",
      "Epoch 35/128\n",
      "8000/8000 [==============================] - 1s 172us/step - loss: 1.3769e-04 - acc: 0.9819 - val_loss: 1.7109e-04 - val_acc: 0.9835\n",
      "Epoch 36/128\n",
      "8000/8000 [==============================] - 1s 116us/step - loss: 1.3938e-04 - acc: 0.9821 - val_loss: 1.2979e-04 - val_acc: 0.9815\n",
      "Epoch 37/128\n",
      "8000/8000 [==============================] - 1s 122us/step - loss: 1.3502e-04 - acc: 0.9808 - val_loss: 1.2085e-04 - val_acc: 0.9820\n",
      "Epoch 38/128\n",
      "8000/8000 [==============================] - 1s 156us/step - loss: 1.2763e-04 - acc: 0.9826 - val_loss: 1.2579e-04 - val_acc: 0.9815\n",
      "Epoch 39/128\n",
      "8000/8000 [==============================] - 1s 149us/step - loss: 1.2839e-04 - acc: 0.9828 - val_loss: 1.2017e-04 - val_acc: 0.9785\n",
      "Epoch 40/128\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.2501e-04 - acc: 0.9820 - val_loss: 1.2550e-04 - val_acc: 0.9810\n",
      "Epoch 41/128\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 1.2086e-04 - acc: 0.9825 - val_loss: 1.2259e-04 - val_acc: 0.9800\n",
      "Epoch 42/128\n",
      "8000/8000 [==============================] - 1s 160us/step - loss: 1.1703e-04 - acc: 0.9831 - val_loss: 1.1923e-04 - val_acc: 0.9815\n",
      "Epoch 43/128\n",
      "8000/8000 [==============================] - 2s 188us/step - loss: 1.1459e-04 - acc: 0.9828 - val_loss: 1.1246e-04 - val_acc: 0.9795\n",
      "Epoch 44/128\n",
      "8000/8000 [==============================] - 1s 182us/step - loss: 1.1275e-04 - acc: 0.9813 - val_loss: 1.1335e-04 - val_acc: 0.9825\n",
      "Epoch 45/128\n",
      "8000/8000 [==============================] - 1s 126us/step - loss: 1.1522e-04 - acc: 0.9824 - val_loss: 1.1713e-04 - val_acc: 0.9820\n",
      "Epoch 46/128\n",
      "8000/8000 [==============================] - 1s 155us/step - loss: 1.1454e-04 - acc: 0.9831 - val_loss: 1.0646e-04 - val_acc: 0.9820\n",
      "Epoch 47/128\n",
      "8000/8000 [==============================] - 1s 115us/step - loss: 1.1306e-04 - acc: 0.9828 - val_loss: 1.0577e-04 - val_acc: 0.9815\n",
      "Epoch 48/128\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 1.0552e-04 - acc: 0.9830 - val_loss: 1.0459e-04 - val_acc: 0.9770\n",
      "Epoch 49/128\n",
      "8000/8000 [==============================] - 1s 143us/step - loss: 1.1007e-04 - acc: 0.9825 - val_loss: 1.0590e-04 - val_acc: 0.9815\n",
      "Epoch 50/128\n",
      "8000/8000 [==============================] - 1s 145us/step - loss: 1.0397e-04 - acc: 0.9834 - val_loss: 1.0523e-04 - val_acc: 0.9780\n",
      "Epoch 51/128\n",
      "8000/8000 [==============================] - 1s 123us/step - loss: 1.0307e-04 - acc: 0.9830 - val_loss: 1.1358e-04 - val_acc: 0.9795\n",
      "Epoch 52/128\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 1.0163e-04 - acc: 0.9825 - val_loss: 9.4397e-05 - val_acc: 0.9810\n",
      "Epoch 53/128\n",
      "8000/8000 [==============================] - 1s 128us/step - loss: 9.8842e-05 - acc: 0.9830 - val_loss: 9.2488e-05 - val_acc: 0.9805\n",
      "Epoch 54/128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 142us/step - loss: 9.9731e-05 - acc: 0.9839 - val_loss: 1.0212e-04 - val_acc: 0.9805\n",
      "Epoch 55/128\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 9.3268e-05 - acc: 0.9843 - val_loss: 9.4157e-05 - val_acc: 0.9795\n",
      "Epoch 56/128\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 9.7570e-05 - acc: 0.9832 - val_loss: 8.8930e-05 - val_acc: 0.9810\n",
      "Epoch 57/128\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 9.1455e-05 - acc: 0.9846 - val_loss: 8.7366e-05 - val_acc: 0.9795\n",
      "Epoch 58/128\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 9.1248e-05 - acc: 0.9834 - val_loss: 9.5811e-05 - val_acc: 0.9815\n",
      "Epoch 59/128\n",
      "8000/8000 [==============================] - 1s 114us/step - loss: 9.1093e-05 - acc: 0.9832 - val_loss: 8.7049e-05 - val_acc: 0.9845\n",
      "Epoch 60/128\n",
      "8000/8000 [==============================] - 1s 146us/step - loss: 8.7577e-05 - acc: 0.9851 - val_loss: 8.5949e-05 - val_acc: 0.9815\n",
      "Epoch 61/128\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 8.5253e-05 - acc: 0.9841 - val_loss: 8.7192e-05 - val_acc: 0.9830\n",
      "Epoch 62/128\n",
      "8000/8000 [==============================] - 2s 195us/step - loss: 8.5378e-05 - acc: 0.9835 - val_loss: 8.1095e-05 - val_acc: 0.9830\n",
      "Epoch 63/128\n",
      "8000/8000 [==============================] - 1s 138us/step - loss: 8.5557e-05 - acc: 0.9848 - val_loss: 8.7510e-05 - val_acc: 0.9825\n",
      "Epoch 64/128\n",
      "8000/8000 [==============================] - 1s 128us/step - loss: 7.9994e-05 - acc: 0.9841 - val_loss: 8.0622e-05 - val_acc: 0.9845\n",
      "Epoch 65/128\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 8.2997e-05 - acc: 0.9852 - val_loss: 8.6717e-05 - val_acc: 0.9820\n",
      "Epoch 66/128\n",
      "8000/8000 [==============================] - 1s 155us/step - loss: 8.1194e-05 - acc: 0.9838 - val_loss: 8.1813e-05 - val_acc: 0.9835\n",
      "Epoch 67/128\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 7.9385e-05 - acc: 0.9848 - val_loss: 8.7148e-05 - val_acc: 0.9835\n",
      "Epoch 68/128\n",
      "8000/8000 [==============================] - 1s 133us/step - loss: 7.9156e-05 - acc: 0.9852 - val_loss: 8.0103e-05 - val_acc: 0.9855\n",
      "Epoch 69/128\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 8.2597e-05 - acc: 0.9831 - val_loss: 7.5579e-05 - val_acc: 0.9835\n",
      "Epoch 70/128\n",
      "8000/8000 [==============================] - 1s 126us/step - loss: 7.7525e-05 - acc: 0.9830 - val_loss: 8.1544e-05 - val_acc: 0.9845\n",
      "Epoch 71/128\n",
      "8000/8000 [==============================] - 1s 133us/step - loss: 7.8804e-05 - acc: 0.9843 - val_loss: 8.4933e-05 - val_acc: 0.9810\n",
      "Epoch 72/128\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 7.7286e-05 - acc: 0.9844 - val_loss: 7.0740e-05 - val_acc: 0.9845\n",
      "Epoch 73/128\n",
      "8000/8000 [==============================] - 1s 134us/step - loss: 7.3240e-05 - acc: 0.9846 - val_loss: 7.3908e-05 - val_acc: 0.9840\n",
      "Epoch 74/128\n",
      "8000/8000 [==============================] - 1s 108us/step - loss: 7.4705e-05 - acc: 0.9856 - val_loss: 6.8317e-05 - val_acc: 0.9820\n",
      "Epoch 75/128\n",
      "8000/8000 [==============================] - 1s 160us/step - loss: 7.3748e-05 - acc: 0.9849 - val_loss: 7.7610e-05 - val_acc: 0.9820\n",
      "Epoch 76/128\n",
      "8000/8000 [==============================] - 1s 128us/step - loss: 7.2837e-05 - acc: 0.9841 - val_loss: 7.8901e-05 - val_acc: 0.9785\n",
      "Epoch 77/128\n",
      "8000/8000 [==============================] - 1s 117us/step - loss: 6.8795e-05 - acc: 0.9841 - val_loss: 6.7914e-05 - val_acc: 0.9845\n",
      "Epoch 78/128\n",
      "8000/8000 [==============================] - 1s 172us/step - loss: 7.0700e-05 - acc: 0.9835 - val_loss: 8.6336e-05 - val_acc: 0.9830\n",
      "Epoch 79/128\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 7.8860e-05 - acc: 0.9841 - val_loss: 1.0872e-04 - val_acc: 0.9770\n",
      "Epoch 80/128\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 7.0838e-05 - acc: 0.9846 - val_loss: 6.6075e-05 - val_acc: 0.9825\n",
      "Epoch 81/128\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 6.8228e-05 - acc: 0.9844 - val_loss: 6.8807e-05 - val_acc: 0.9820\n",
      "Epoch 82/128\n",
      "8000/8000 [==============================] - 1s 134us/step - loss: 6.7135e-05 - acc: 0.9865 - val_loss: 8.2592e-05 - val_acc: 0.9820\n",
      "Epoch 83/128\n",
      "8000/8000 [==============================] - 1s 119us/step - loss: 7.1154e-05 - acc: 0.9850 - val_loss: 6.5601e-05 - val_acc: 0.9840\n",
      "Epoch 84/128\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 6.6236e-05 - acc: 0.9845 - val_loss: 6.9900e-05 - val_acc: 0.9815\n",
      "Epoch 85/128\n",
      "8000/8000 [==============================] - 1s 116us/step - loss: 7.1376e-05 - acc: 0.9845 - val_loss: 6.4954e-05 - val_acc: 0.9830\n",
      "Epoch 86/128\n",
      "8000/8000 [==============================] - 1s 123us/step - loss: 7.0077e-05 - acc: 0.9860 - val_loss: 6.4261e-05 - val_acc: 0.9830\n",
      "Epoch 87/128\n",
      "8000/8000 [==============================] - 1s 116us/step - loss: 6.8368e-05 - acc: 0.9858 - val_loss: 6.2348e-05 - val_acc: 0.9865\n",
      "Epoch 88/128\n",
      "8000/8000 [==============================] - 1s 149us/step - loss: 6.2465e-05 - acc: 0.9858 - val_loss: 6.4484e-05 - val_acc: 0.9835\n",
      "Epoch 89/128\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 6.5179e-05 - acc: 0.9858 - val_loss: 6.4995e-05 - val_acc: 0.9865\n",
      "Epoch 90/128\n",
      "8000/8000 [==============================] - 1s 167us/step - loss: 6.3986e-05 - acc: 0.9854 - val_loss: 6.1164e-05 - val_acc: 0.9850\n",
      "Epoch 91/128\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 6.3955e-05 - acc: 0.9849 - val_loss: 6.1052e-05 - val_acc: 0.9860\n",
      "Epoch 92/128\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 6.6256e-05 - acc: 0.9852 - val_loss: 6.2235e-05 - val_acc: 0.9860\n",
      "Epoch 93/128\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 6.0901e-05 - acc: 0.9850 - val_loss: 6.0547e-05 - val_acc: 0.9850\n",
      "Epoch 94/128\n",
      "8000/8000 [==============================] - 1s 122us/step - loss: 6.1556e-05 - acc: 0.9852 - val_loss: 6.5350e-05 - val_acc: 0.9805\n",
      "Epoch 95/128\n",
      "8000/8000 [==============================] - 1s 134us/step - loss: 6.1577e-05 - acc: 0.9861 - val_loss: 6.7923e-05 - val_acc: 0.9835\n",
      "Epoch 96/128\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 6.1485e-05 - acc: 0.9850 - val_loss: 6.3164e-05 - val_acc: 0.9845\n",
      "Epoch 97/128\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 6.1324e-05 - acc: 0.9864 - val_loss: 6.0653e-05 - val_acc: 0.9845\n",
      "Epoch 98/128\n",
      "8000/8000 [==============================] - 1s 152us/step - loss: 6.1926e-05 - acc: 0.9854 - val_loss: 6.5379e-05 - val_acc: 0.9845\n",
      "Epoch 99/128\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 5.8946e-05 - acc: 0.9859 - val_loss: 5.9966e-05 - val_acc: 0.9835\n",
      "Epoch 100/128\n",
      "8000/8000 [==============================] - 1s 152us/step - loss: 6.0553e-05 - acc: 0.9856 - val_loss: 6.4839e-05 - val_acc: 0.9850\n",
      "Epoch 101/128\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 6.0572e-05 - acc: 0.9862 - val_loss: 5.7261e-05 - val_acc: 0.9850\n",
      "Epoch 102/128\n",
      "8000/8000 [==============================] - 1s 160us/step - loss: 6.0540e-05 - acc: 0.9850 - val_loss: 6.4965e-05 - val_acc: 0.9870\n",
      "Epoch 103/128\n",
      "8000/8000 [==============================] - 1s 119us/step - loss: 6.1028e-05 - acc: 0.9849 - val_loss: 6.3726e-05 - val_acc: 0.9880\n",
      "Epoch 104/128\n",
      "8000/8000 [==============================] - 1s 133us/step - loss: 5.6876e-05 - acc: 0.9848 - val_loss: 6.8298e-05 - val_acc: 0.9790\n",
      "Epoch 105/128\n",
      "8000/8000 [==============================] - 1s 123us/step - loss: 6.0628e-05 - acc: 0.9852 - val_loss: 5.8898e-05 - val_acc: 0.9835\n",
      "Epoch 106/128\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 5.9838e-05 - acc: 0.9859 - val_loss: 6.3555e-05 - val_acc: 0.9855\n",
      "Epoch 107/128\n",
      "8000/8000 [==============================] - 1s 151us/step - loss: 5.7502e-05 - acc: 0.9856 - val_loss: 5.7632e-05 - val_acc: 0.9840\n",
      "Epoch 108/128\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 5.6029e-05 - acc: 0.9850 - val_loss: 7.1355e-05 - val_acc: 0.9855\n",
      "Epoch 109/128\n",
      "8000/8000 [==============================] - 1s 137us/step - loss: 5.7298e-05 - acc: 0.9856 - val_loss: 6.0340e-05 - val_acc: 0.9800\n",
      "Epoch 110/128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 113us/step - loss: 5.6908e-05 - acc: 0.9861 - val_loss: 7.2535e-05 - val_acc: 0.9815\n",
      "Epoch 111/128\n",
      "8000/8000 [==============================] - 1s 167us/step - loss: 5.5565e-05 - acc: 0.9855 - val_loss: 6.4281e-05 - val_acc: 0.9845\n",
      "Epoch 112/128\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 5.4595e-05 - acc: 0.9860 - val_loss: 5.8430e-05 - val_acc: 0.9815\n",
      "Epoch 113/128\n",
      "8000/8000 [==============================] - 1s 121us/step - loss: 5.8998e-05 - acc: 0.9856 - val_loss: 5.6974e-05 - val_acc: 0.9825\n",
      "Epoch 114/128\n",
      "8000/8000 [==============================] - 1s 136us/step - loss: 5.7527e-05 - acc: 0.9865 - val_loss: 6.1531e-05 - val_acc: 0.9830\n",
      "Epoch 115/128\n",
      "8000/8000 [==============================] - 1s 145us/step - loss: 5.5159e-05 - acc: 0.9839 - val_loss: 6.5039e-05 - val_acc: 0.9825\n",
      "Epoch 116/128\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 5.4586e-05 - acc: 0.9856 - val_loss: 5.7951e-05 - val_acc: 0.9850\n",
      "Epoch 117/128\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 5.4008e-05 - acc: 0.9849 - val_loss: 5.5078e-05 - val_acc: 0.9855\n",
      "Epoch 118/128\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 5.3217e-05 - acc: 0.9844 - val_loss: 5.6255e-05 - val_acc: 0.9795\n",
      "Epoch 119/128\n",
      "8000/8000 [==============================] - 1s 183us/step - loss: 5.6215e-05 - acc: 0.9859 - val_loss: 6.5219e-05 - val_acc: 0.9810\n",
      "Epoch 120/128\n",
      "8000/8000 [==============================] - 1s 149us/step - loss: 5.8065e-05 - acc: 0.9856 - val_loss: 5.5879e-05 - val_acc: 0.9845\n",
      "Epoch 121/128\n",
      "8000/8000 [==============================] - 2s 189us/step - loss: 5.4186e-05 - acc: 0.9855 - val_loss: 5.2318e-05 - val_acc: 0.9805\n",
      "Epoch 122/128\n",
      "8000/8000 [==============================] - 1s 146us/step - loss: 5.0868e-05 - acc: 0.9862 - val_loss: 5.4218e-05 - val_acc: 0.9830\n",
      "Epoch 123/128\n",
      "8000/8000 [==============================] - 1s 132us/step - loss: 5.3033e-05 - acc: 0.9850 - val_loss: 5.4899e-05 - val_acc: 0.9805\n",
      "Epoch 124/128\n",
      "8000/8000 [==============================] - 1s 123us/step - loss: 5.3649e-05 - acc: 0.9854 - val_loss: 5.3828e-05 - val_acc: 0.9855\n",
      "Epoch 125/128\n",
      "8000/8000 [==============================] - 1s 172us/step - loss: 5.4055e-05 - acc: 0.9855 - val_loss: 5.6495e-05 - val_acc: 0.9840\n",
      "Epoch 126/128\n",
      "8000/8000 [==============================] - 1s 135us/step - loss: 5.1528e-05 - acc: 0.9865 - val_loss: 5.5006e-05 - val_acc: 0.9815\n",
      "Epoch 127/128\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 5.1459e-05 - acc: 0.9850 - val_loss: 5.0355e-05 - val_acc: 0.9815\n",
      "Epoch 128/128\n",
      "8000/8000 [==============================] - 1s 183us/step - loss: 5.1023e-05 - acc: 0.9855 - val_loss: 4.8519e-05 - val_acc: 0.9835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fafbe5c9160>"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    np.asarray(X).reshape(-1, 32, 32, 1), \n",
    "    np.asarray(y),\n",
    "    batch_size=1,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    np.asarray(X).reshape(-1, 32, 32, 1), \n",
    "    np.asarray(y),\n",
    "    batch_size=8,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    np.asarray(X).reshape(-1, 32, 32, 1), \n",
    "    np.asarray(y),\n",
    "    epochs=128,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, size, col, row = generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(np.asarray(img).reshape(1, 32, 32, 1) / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 5 rounded prediction: 5.0, row 5.038093328475952\n",
      "pos x: 8 rounded prediction: 8.0, row 7.755105972290039\n",
      "pos y: 25 rounded prediction: 25.0, row 25.22989273071289\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size: {size} rounded prediction: {round(preds[0][0] * 10)}, row {preds[0][0] * 10}\")\n",
    "print(f\"pos x: {col} rounded prediction: {round(preds[0][1] * 32)}, row {preds[0][1] * 32}\")\n",
    "print(f\"pos y: {row} rounded prediction: {round(preds[0][2] * 32)}, row {preds[0][2] * 32}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAAAIUlEQVR4nGNgGAUMDAwMjDhl/kOkmQiZQAcFo2AU0BkAABuMAQql+gVUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32 at 0x7FAFBE5AA550>"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
